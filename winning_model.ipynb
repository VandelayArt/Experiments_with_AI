{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Winning Lottery Sequence Dataset</h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Step 1: Import libraries</h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Step 2: Load Data</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the winning sequences dataset\n",
    "data = pd.read_excel('Lotto_sequence.xlsx')\n",
    "\n",
    "# Extract the six number columns and the bonus number column\n",
    "X = data[['Number 1', 'Number 2', 'Number 3', 'Number 4', 'Number 5', 'Number 6', 'Bonus']]\n",
    "y = data[['Number 1', 'Number 2', 'Number 3', 'Number 4', 'Number 5', 'Number 6', 'Bonus']]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Step 3: Use a labelencoder on the dataset</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encode the data using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "for column in X.columns:\n",
    "    X[column] = label_encoder.fit_transform(X[column])\n",
    "    y[column] = label_encoder.fit_transform(y[column])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Step 4: Scale and Reshape Dataset</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape the data to match the input shape of the model\n",
    "X_reshaped = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], 1)\n",
    "y_values = y.values\n",
    "y_reshaped = y_values.reshape(y_values.shape[0], y_values.shape[1], 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Step 5: Defining the Neural Network models</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(X_reshaped.shape[1], X_reshaped.shape[2])))\n",
    "model.add(Dense(7))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Step 6: Compile Model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Step 7: Set up parameters and fit model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "19/19 [==============================] - 10s 35ms/step - loss: 398.2426\n",
      "Epoch 2/50\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 392.7128: 0s - loss: 393.94\n",
      "Epoch 3/50\n",
      "19/19 [==============================] - 1s 43ms/step - loss: 352.4136\n",
      "Epoch 4/50\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 117.4249\n",
      "Epoch 5/50\n",
      "19/19 [==============================] - 0s 26ms/step - loss: 72.3486\n",
      "Epoch 6/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 59.9474\n",
      "Epoch 7/50\n",
      "19/19 [==============================] - 0s 26ms/step - loss: 54.3482\n",
      "Epoch 8/50\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 50.9023\n",
      "Epoch 9/50\n",
      "19/19 [==============================] - 0s 26ms/step - loss: 49.2072\n",
      "Epoch 10/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 48.5493\n",
      "Epoch 11/50\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 48.0654\n",
      "Epoch 12/50\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 47.6814 0s - loss: 4\n",
      "Epoch 13/50\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 47.1551\n",
      "Epoch 14/50\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 46.5759\n",
      "Epoch 15/50\n",
      "19/19 [==============================] - 1s 22ms/step - loss: 46.0796\n",
      "Epoch 16/50\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 45.3680\n",
      "Epoch 17/50\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 44.7671\n",
      "Epoch 18/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 44.1034\n",
      "Epoch 19/50\n",
      "19/19 [==============================] - 1s 25ms/step - loss: 43.1737\n",
      "Epoch 20/50\n",
      "19/19 [==============================] - 0s 26ms/step - loss: 42.2251 0s - loss: 42.\n",
      "Epoch 21/50\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 41.1955\n",
      "Epoch 22/50\n",
      "19/19 [==============================] - 1s 26ms/step - loss: 39.9753\n",
      "Epoch 23/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 38.2546\n",
      "Epoch 24/50\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 35.7108\n",
      "Epoch 25/50\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 33.2760\n",
      "Epoch 26/50\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 31.0898\n",
      "Epoch 27/50\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 29.5185\n",
      "Epoch 28/50\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 28.3825\n",
      "Epoch 29/50\n",
      "19/19 [==============================] - 1s 26ms/step - loss: 27.0511\n",
      "Epoch 30/50\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 26.3984\n",
      "Epoch 31/50\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 25.5308\n",
      "Epoch 32/50\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 24.3193\n",
      "Epoch 33/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 23.4320\n",
      "Epoch 34/50\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 22.6463\n",
      "Epoch 35/50\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 21.8173\n",
      "Epoch 36/50\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 20.9855\n",
      "Epoch 37/50\n",
      "19/19 [==============================] - 0s 26ms/step - loss: 19.5780\n",
      "Epoch 38/50\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 17.9866 0s - loss:\n",
      "Epoch 39/50\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 17.8520 0s - loss: 17.85\n",
      "Epoch 40/50\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 15.6887\n",
      "Epoch 41/50\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 13.9053\n",
      "Epoch 42/50\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 12.3674\n",
      "Epoch 43/50\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 11.1003\n",
      "Epoch 44/50\n",
      "19/19 [==============================] - 0s 26ms/step - loss: 10.0013\n",
      "Epoch 45/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 9.4009\n",
      "Epoch 46/50\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 8.9027\n",
      "Epoch 47/50\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 8.2948\n",
      "Epoch 48/50\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 8.3843\n",
      "Epoch 49/50\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 8.0507\n",
      "Epoch 50/50\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 8.1512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fed82e2408>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the data\n",
    "model.fit(X_reshaped, y_reshaped, epochs=50, batch_size=64)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Step 8: Save Model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('new_lotto_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0         1         2         3         4         5      6\n",
      "0     Number 1  Number 2  Number 3  Number 4  Number 5  Number 6  Bonus\n",
      "1         12.0      20.0      30.0      31.0      32.0      39.0   34.0\n",
      "2          3.0       9.0      10.0      25.0      31.0      34.0   24.0\n",
      "3         15.0      17.0      22.0      24.0      34.0      38.0   30.0\n",
      "4         14.0      18.0      27.0      33.0      41.0      42.0    1.0\n",
      "...        ...       ...       ...       ...       ...       ...    ...\n",
      "1199      25.0      27.0      29.0      31.0      42.0      44.0   17.0\n",
      "1200       2.0      11.0      18.0      20.0      39.0      42.0   24.0\n",
      "1201      11.0      14.0      19.0      30.0      38.0      41.0   17.0\n",
      "1202      17.0      18.0      20.0      23.0      24.0      41.0    1.0\n",
      "1203       1.0       2.0      10.0      18.0      28.0      41.0   29.0\n",
      "\n",
      "[1204 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('new_lotto_model.h5')\n",
    "\n",
    "# Load the test data from the Excel file\n",
    "test_data = pd.read_excel('Lotto_sequence.xlsx', header=None)\n",
    "test_data = test_data.astype(str)\n",
    "\n",
    "print(test_data)\n",
    "# Select the last 7 rows of the dataframe\n",
    "test_data = test_data.tail(7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 49 into shape (1,7,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17872/2992832606.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Reshape the test data to be compatible with the model input shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mX_reshaped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Make predictions on the test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 49 into shape (1,7,1)"
     ]
    }
   ],
   "source": [
    "\n",
    "# Apply label encoding to the test data\n",
    "label_encoder = LabelEncoder()\n",
    "for i in range(7):\n",
    "    test_data[i] = label_encoder.fit_transform(test_data[i])\n",
    "\n",
    "# Reshape the test data to be compatible with the model input shape\n",
    "X_reshaped = np.array(test_data).reshape(1, 7, 1)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.predict(X_reshaped)\n",
    "\n",
    "# Convert the predictions back to combination labels\n",
    "top_combinations = label_encoder.inverse_transform(predictions[0].argsort()[-10:][::-1])\n",
    "\n",
    "# Print the top 10 predicted combinations\n",
    "for i, combination in enumerate(top_combinations):\n",
    "    print(f\"Rank {i+1}: {combination}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
